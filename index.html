<!DOCTYPE html>
<html>
<head>
Â  <meta charset="utf-8">
Â  <meta name="description"
Â  Â  Â  Â  content="OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning ">
Â  <meta name="keywords" content="OCRBench v2">
Â  <meta name="viewport" content="width=device-width, initial-scale=1">
Â  <title>OCRBench v2</title>

Â  Â  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
Â  <script>
Â  Â  window.dataLayer = window.dataLayer || [];
Â  Â  function gtag() { dataLayer.push(arguments); }
Â  Â  gtag('js', new Date());
Â  Â  gtag('config', 'G-PYVRSFMDRL');
Â  </script>

Â  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
Â  <link rel="stylesheet" href="./static/css/bulma.min.css">
Â  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
Â  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
Â  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
Â  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
Â  <link rel="stylesheet" href="./static/css/index.css">
Â  <link rel="icon" href="./static/images/web.png">
Â  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">

Â  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
Â  <script defer src="./static/js/fontawesome.all.min.js"></script>
Â  <script src="./static/js/bulma-carousel.min.js"></script>
Â  <script src="./static/js/bulma-slider.min.js"></script>
Â  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
Â  <div class="navbar-brand">
Â  Â  <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
Â  Â  Â  <span aria-hidden="true"></span>
Â  Â  Â  <span aria-hidden="true"></span>
Â  Â  Â  <span aria-hidden="true"></span>
Â  Â  </a>
Â  </div>
</nav>

<section class="hero">
Â  <div class="hero-body">
Â  Â  <div class="container is-max-desktop">
Â  Â  Â  <div class="columns is-centered">
Â  Â  Â  Â  <div class="column has-text-centered">
Â  Â  Â  Â  Â  <h1 class="title is-1 publication-title">OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning</h1>
Â  Â  Â  Â  Â  <div class="column has-text-centered">
Â  Â  Â  Â  Â  Â  <div class="publication-links">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="link-block">
Â  Â  Â  Â  Â  Â  Â  Â  <a href="https://arxiv.org/abs/2501.00321" class="external-link button is-normal is-rounded is-dark">
Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="icon"><i class="ai ai-arxiv"></i></span>
Â  Â  Â  Â  Â  Â  Â  Â  Â  <span>arXiv</span>
Â  Â  Â  Â  Â  Â  Â  Â  </a>
Â  Â  Â  Â  Â  Â  Â  </span>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="link-block">
Â  Â  Â  Â  Â  Â  Â  Â  <a href="https://github.com/Yuliang-Liu/MultimodalOCR" class="external-link button is-normal is-rounded is-dark">
Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="icon"><i class="fab fa-github"></i></span>
Â  Â  Â  Â  Â  Â  Â  Â  Â  <span>Code</span>
Â  Â  Â  Â  Â  Â  Â  Â  </a>
Â  Â  Â  Â  Â  Â  Â  </span>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="link-block">
Â  Â  Â  Â  Â  Â  Â  Â  <a href="https://drive.google.com/file/d/1Hk1TMu--7nr5vJ7iaNwMQZ_Iw9W_KI3C/view?usp=sharing" class="external-link button is-normal is-rounded is-dark">
Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="icon"><i class="far fa-images"></i></span>
Â  Â  Â  Â  Â  Â  Â  Â  Â  <span>Data</span>
Â  Â  Â  Â  Â  Â  Â  Â  </a>
Â  Â  Â  Â  Â  Â  Â  </span>
Â  Â  Â  Â  Â  Â  Â  <span class="link-block">
Â  Â  Â  Â  Â  Â  Â  Â  <a href="https://huggingface.co/datasets/ling99/OCRBench_v2" class="external-link button is-normal is-rounded is-dark">
Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="icon has-text-white"><i class="fa-solid fa-trophy" aria-hidden="true"></i></span>
Â  Â  Â  Â  Â  Â  Â  Â  Â  <span>Huggingface</span>
Â  Â  Â  Â  Â  Â  Â  Â  </a>
Â  Â  Â  Â  Â  Â  Â  </span>
Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  </div>
Â  Â  Â  </div>
Â  Â  </div>
Â  </div>
</section>

<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<title>Leaderboard</title>
<style>
Â  Â  body {
Â  Â  Â  background-color: #ffffff;
Â  Â  Â  font-family: Arial, sans-serif;
Â  Â  Â  margin: 0;
Â  Â  Â  padding: 0;
Â  Â  }
Â  Â  .section { padding: 2rem 1rem; }
Â  Â  .container { max-width: 1200px; margin: auto; }
Â  Â  h2.title { font-size: 2rem; margin-bottom: 1rem; text-align: center; color: #333; }
Â  Â  .content p { font-size: 1rem; font-weight: 600; margin-top: 2rem; margin-bottom: 0.5rem; text-align: center; }
Â  Â  table { width: 100%; max-width: 100%; border-collapse: collapse; margin: 0 auto 2rem auto; font-size: 14px; text-align: center; box-shadow: 0 0 8px rgba(0,0,0,0.05); }
Â  Â  thead { background-color: #e6f0fa; color: #333; }
Â  Â  thead tr td { font-weight: bold; padding: 0.6rem; border-bottom: 2px solid #ccc; }
Â  Â  tbody tr td { padding: 0.5rem; border-bottom: 1px solid #eee; }
Â  Â  tbody tr:nth-child(even) { background-color: #f9fcff; }
Â  Â  tbody tr:hover { background-color: #e0f3ff; transition: background-color 0.2s ease; }
Â  Â  @media (max-width: 768px) { table { font-size: 12px; } }
Â  Â  .table-title { font-weight: bold; text-align: center; margin: 2rem 0 1rem 0; }
Â  Â  table { position: relative; border-collapse: collapse; }
Â  Â  table td:nth-child(4), table th:nth-child(4) { position: relative; z-index: 2; font-weight: 700; background: rgba(240,248,255,.60); border-bottom: none!important; }
Â  Â  table tr:nth-child(even) td:nth-child(4) { background: rgba(240,248,255,.60); }
Â  Â  table tr:first-child td:nth-child(4) { border-top-left-radius:12px; border-top-right-radius:12px }
Â  Â  table tr:last-child td:nth-child(4) { border-bottom-left-radius:12px; border-bottom-right-radius:12px }
Â  Â  table::after { content:''; position:absolute; top:0; bottom:0; left:var(--avg-left,0); width:var(--avg-width,0); border-radius:12px; pointer-events:none; background:rgba(240,248,255,.25); box-shadow:0 0 25px 16px rgba(100,150,255,.45); z-index:0; }
    
    /* æ–°å¢ï¼šæ—¥æœŸé€‰æ‹©å™¨æ ·å¼ */
    .date-selector-container {
        text-align: center;
        margin-bottom: 2rem;
    }
    .date-selector-container label {
        font-weight: bold;
        margin-right: 10px;
        color: #333;
    }
    #date-selector {
        padding: 8px 12px;
        border-radius: 6px;
        border: 1px solid #ccc;
        font-size: 16px;
        background-color: #f9fcff;
    }
</style>
</head>
<body>

<section class="section">
Â  <div class="container">
Â  Â  <h2 class="title">Leaderboard on Private data</h2>

    <div class="date-selector-container">
        <label for="date-selector">é€‰æ‹©æ¦œå•æ—¥æœŸ:</label>
        <select id="date-selector">
            <option value="2025-06-23">2025-06-23</option>
            <option value="2025-03-23">2025-03-23 (å†å²æ ·æœ¬)</option>
        </select>
    </div>

Â  Â  <div class="content">
Â  Â  Â  <p class="table-title">Performance of LMMs on English tasks</p>
Â  Â  Â  <table id="english-leaderboard"> Â  Â  Â  Â  <thead>
Â  Â  Â  Â  Â  <tr>
Â  Â  Â  Â  Â  Â  <td>Rank</td>
Â  Â  Â  Â  Â  Â  <td>Method</td>
Â  Â  Â  Â  Â  Â  <td>LLM Size</td>
Â  Â  Â  Â  Â  Â  <td class="highlight-average">Average</td>
Â  Â  Â  Â  Â  Â  <td>Recognition</td>
Â  Â  Â  Â  Â  Â  <td>Referring</td>
Â  Â  Â  Â  Â  Â  <td>Spotting</td>
Â  Â  Â  Â  Â  Â  <td>Extraction</td>
Â  Â  Â  Â  Â  Â  <td>Parsing</td>
Â  Â  Â  Â  Â  Â  <td>Calculation</td>
Â  Â  Â  Â  Â  Â  <td>Understanding</td>
Â  Â  Â  Â  Â  Â  <td>Reasoning</td>
Â  Â  Â  Â  Â  </tr>
Â  Â  Â  Â  </thead>
Â  Â  Â  Â  <tbody id="english-leaderboard-tbody"> Â  Â  Â  Â  </tbody>
Â  Â  Â  </table>

Â  Â  Â  <p class="table-title">Performance of LMMs on Chinese tasks</p>
Â  Â  Â  <table id="chinese-leaderboard"> Â  Â  Â  Â  <thead>
Â  Â  Â  Â  Â  <tr>
Â  Â  Â  Â  Â  Â  <td>Rank</td>
Â  Â  Â  Â  Â  Â  <td>Method</td>
Â  Â  Â  Â  Â  Â  <td>LLM Size</td>
Â  Â  Â  Â  Â  Â  <td class="highlight-average">Average</td>
Â  Â  Â  Â  Â  Â  <td>Recognition</td>
Â  Â  Â  Â  Â  Â  <td>Extraction</td>
Â  Â  Â  Â  Â  Â  <td>Parsing</td>
Â  Â  Â  Â  Â  Â  <td>Understanding</td>
Â  Â  Â  Â  Â  Â  <td>Reasoning</td>
Â  Â  Â  Â  Â  </tr>
Â  Â  Â  Â  </thead>
Â  Â  Â  Â  <tbody id="chinese-leaderboard-tbody"> Â  Â  Â  Â  </tbody>
Â  Â  Â  </table>

Â  Â  Â  <br>Â 
      Â  Â  </div>
Â  </div>
</section>

<script>
// æ­¥éª¤ 1: å°†æ‰€æœ‰æ•°æ®ç»“æ„åŒ–
// æ‚¨å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šæ—¥æœŸå’Œå¯¹åº”çš„æ•°æ®
const leaderboardData = {
    "2025-06-23": {
        english: [
            { rank: 1, method: "Gemini-2.5-ProğŸ¥‡", llm_size: "-", average: 59.3, recognition: 70.9, referring: 45.8, spotting: 13.4, extraction: 93.7, parsing: 26.9, calculation: 84.6, understanding: 75.8, reasoning: 63.0 },
            { rank: 2, method: "Llama-3.1-Nemotron-Nano-VL-8B-V1ğŸ¥ˆ", llm_size: "-", average: 56.4, recognition: 62.9, referring: 61.3, spotting: 68.6, extraction: 88.2, parsing: 10.0, calculation: 44.1, understanding: 75.3, reasoning: 41.0 },
            { rank: 3, method: "Gemini1.5-ProğŸ¥‰", llm_size: "-", average: 51.6, recognition: 59.1, referring: 41.2, spotting: 6.6, extraction: 89.5, parsing: 22.4, calculation: 54.7, understanding: 78.8, reasoning: 60.3 },
            { rank: 4, method: "GPT-4o", llm_size: "-", average: 47.6, recognition: 58.6, referring: 23.4, spotting: 0.0, extraction: 87.4, parsing: 23.1, calculation: 51.6, understanding: 74.4, reasoning: 62.3 },
            { rank: 5, method: "Claude3.5-sonnet", llm_size: "-", average: 47.5, recognition: 52.9, referring: 24.9, spotting: 2.5, extraction: 86.9, parsing: 23.8, calculation: 61.4, understanding: 74.4, reasoning: 53.0 },
            { rank: 6, method: "Step-1V", llm_size: "-", average: 46.8, recognition: 56.7, referring: 27.4, spotting: 2.6, extraction: 86.3, parsing: 33.3, calculation: 42.6, understanding: 76.6, reasoning: 48.7 },
            { rank: 7, method: "InternVL3-14B", llm_size: "14B", average: 46.8, recognition: 55.8, referring: 24.5, spotting: 2.1, extraction: 89.3, parsing: 21.0, calculation: 59.5, understanding: 72.0, reasoning: 50.0 },
            { rank: 8, method: "Ovis2-8B", llm_size: "7B", average: 46.1, recognition: 54.2, referring: 20.9, spotting: 0.0, extraction: 83.6, parsing: 24.2, calculation: 54.7, understanding: 74.1, reasoning: 57.3 },
            { rank: 9, method: "InternVL3-8B", llm_size: "8B", average: 45.3, recognition: 49.7, referring: 22.3, spotting: 0.2, extraction: 86.8, parsing: 22.4, calculation: 57.0, understanding: 70.7, reasoning: 53.0 },
            { rank: 10, method: "GPT-4o-mini", llm_size: "-", average: 44.1, recognition: 55.3, referring: 21.8, spotting: 0.0, extraction: 85.4, parsing: 20.6, calculation: 45.2, understanding: 75.5, reasoning: 49.0 }
        ],
        chinese: [
            { rank: 1, method: "Gemini-2.5-ProğŸ¥‡", llm_size: "-", average: 62.2, recognition: 72.0, extraction: 74.0, parsing: 35.2, understanding: 90.0, reasoning: 39.7 },
            { rank: 2, method: "Ovis2-8BğŸ¥ˆ", llm_size: "7B", average: 56.0, recognition: 61.0, extraction: 67.7, parsing: 43.6, understanding: 82.0, reasoning: 25.6 },
            { rank: 3, method: "Gemini1.5-ProğŸ¥‰", llm_size: "-", average: 55.5, recognition: 71.4, extraction: 63.8, parsing: 30.5, understanding: 82.0, reasoning: 29.9 },
            { rank: 4, method: "Kimi-VL-A3B-16B", llm_size: "16B", average: 54.1, recognition: 54.0, extraction: 71.1, parsing: 32.5, understanding: 84.0, reasoning: 28.7 },
            { rank: 5, method: "Step-1V", llm_size: "-", average: 53.4, recognition: 65.2, extraction: 64.9, parsing: 33.1, understanding: 78.0, reasoning: 25.5 },
            { rank: 6, method: "InternVL3-14B", llm_size: "14B", average: 52.8, recognition: 62.1, extraction: 59.5, parsing: 33.2, understanding: 80.0, reasoning: 29.2 },
            { rank: 7, method: "GLM-4v-9B", llm_size: "9B", average: 51.7, recognition: 60.6, extraction: 65.2, parsing: 32.4, understanding: 82.0, reasoning: 18.2 },
            { rank: 8, method: "Qwen2.5-VL-7B", llm_size: "8B", average: 49.5, recognition: 24.4, extraction: 78.9, parsing: 33.1, understanding: 82.0, reasoning: 29.0 },
            { rank: 9, method: "InternVL3-8B", llm_size: "8B", average: 49.0, recognition: 57.7, extraction: 55.8, parsing: 29.9, understanding: 72.0, reasoning: 29.4 },
            { rank: 10, method: "Claude3.5-sonnet", llm_size: "-", average: 48.4, recognition: 34.2, extraction: 62.5, parsing: 35.2, understanding: 78.0, reasoning: 32.2 }
        ]
    },
    "2025-03-23": {
        english: [
            { rank: 1, method: "Gemini-2.5-ProğŸ¥‡", llm_size: "-", average: 58.1, recognition: 69.5, referring: 44.1, spotting: 12.0, extraction: 92.5, parsing: 25.0, calculation: 83.1, understanding: 74.2, reasoning: 62.5 },
            { rank: 2, method: "Gemini1.5-ProğŸ¥ˆ", llm_size: "-", average: 50.2, recognition: 58.0, referring: 40.1, spotting: 5.9, extraction: 88.1, parsing: 21.3, calculation: 53.2, understanding: 77.9, reasoning: 59.1 },
            { rank: 3, method: "Llama-3.1-Nemotron-Nano-VL-8B-V1ğŸ¥‰", llm_size: "-", average: 49.9, recognition: 55.1, referring: 50.2, spotting: 50.1, extraction: 85.0, parsing: 8.0, calculation: 40.1, understanding: 72.1, reasoning: 38.4 },
            { rank: 4, method: "GPT-4o", llm_size: "-", average: 46.5, recognition: 57.2, referring: 22.1, spotting: 0.0, extraction: 86.0, parsing: 22.0, calculation: 50.1, understanding: 73.0, reasoning: 61.2 },
            { rank: 5, method: "Step-1V", llm_size: "-", average: 45.9, recognition: 55.1, referring: 26.0, spotting: 2.1, extraction: 85.2, parsing: 32.1, calculation: 41.3, understanding: 75.1, reasoning: 47.2 },
        ],
        chinese: [
            { rank: 1, method: "Gemini-2.5-ProğŸ¥‡", llm_size: "-", average: 61.0, recognition: 70.0, extraction: 72.5, parsing: 34.1, understanding: 88.9, reasoning: 38.1 },
            { rank: 2, method: "Gemini1.5-ProğŸ¥ˆ", llm_size: "-", average: 54.3, recognition: 70.1, extraction: 62.1, parsing: 29.0, understanding: 81.0, reasoning: 28.1 },
            { rank: 3, method: "Ovis2-8BğŸ¥‰", llm_size: "7B", average: 54.1, recognition: 59.2, extraction: 65.1, parsing: 42.1, understanding: 80.0, reasoning: 24.1 },
            { rank: 4, method: "Step-1V", llm_size: "-", average: 52.9, recognition: 64.1, extraction: 63.2, parsing: 32.0, understanding: 77.0, reasoning: 24.9 },
            { rank: 5, method: "Kimi-VL-A3B-16B", llm_size: "16B", average: 52.5, recognition: 52.1, extraction: 69.0, parsing: 31.0, understanding: 82.1, reasoning: 27.2 },
        ]
    }
};

/**
 * é‡æ–°è®¡ç®—å¹¶åº”ç”¨ç¬¬å››åˆ—çš„é«˜äº®æ¨¡ç³Šæ•ˆæœ
 * è¿™æ˜¯ä»æ‚¨åŸæœ‰è„šæœ¬ä¸­æå–å¹¶å°è£…çš„é€»è¾‘
 */
function recalculateHighlightEffect() {
    document.querySelectorAll('table').forEach(table => {
        const avgCell = table.querySelector('tr:first-child th:nth-child(4), tr:first-child td:nth-child(4)');
        if (!avgCell) return;
        
        const tableRect = table.getBoundingClientRect();
        const cellRect  = avgCell.getBoundingClientRect();
        
        const left  = cellRect.left - tableRect.left;
        const width = cellRect.width;
        
        table.style.setProperty('--avg-left',  `${left}px`);
        table.style.setProperty('--avg-width', `${width}px`);
    });
}


/**
 * æ ¹æ®æ‰€é€‰æ—¥æœŸæ›´æ–°ä¸¤ä¸ªæ’è¡Œæ¦œ
 */
function updateLeaderboards() {
    const selectedDate = document.getElementById('date-selector').value;
    const data = leaderboardData[selectedDate];

    const englishTbody = document.getElementById('english-leaderboard-tbody');
    const chineseTbody = document.getElementById('chinese-leaderboard-tbody');

    // æ¸…ç©ºç°æœ‰è¡¨æ ¼å†…å®¹
    englishTbody.innerHTML = '';
    chineseTbody.innerHTML = '';

    // å¡«å……è‹±æ–‡æ¦œå•
    if (data.english) {
        data.english.forEach(model => {
            const row = document.createElement('tr');
            row.innerHTML = `
                <td>${model.rank}</td>
                <td>${model.method}</td>
                <td>${model.llm_size}</td>
                <td class="highlight-average">${model.average}</td>
                <td>${model.recognition}</td>
                <td>${model.referring}</td>
                <td>${model.spotting}</td>
                <td>${model.extraction}</td>
                <td>${model.parsing}</td>
                <td>${model.calculation}</td>
                <td>${model.understanding}</td>
                <td>${model.reasoning}</td>
            `;
            englishTbody.appendChild(row);
        });
    }

    // å¡«å……ä¸­æ–‡æ¦œå•
    if (data.chinese) {
        data.chinese.forEach(model => {
            const row = document.createElement('tr');
            row.innerHTML = `
                <td>${model.rank}</td>
                <td>${model.method}</td>
                <td>${model.llm_size}</td>
                <td class="highlight-average">${model.average}</td>
                <td>${model.recognition}</td>
                <td>${model.extraction}</td>
                <td>${model.parsing}</td>
                <td>${model.understanding}</td>
                <td>${model.reasoning}</td>
            `;
            chineseTbody.appendChild(row);
        });
    }

    // å…³é”®æ­¥éª¤ï¼šåœ¨è¡¨æ ¼å†…å®¹æ›´æ–°åï¼Œé‡æ–°è®¡ç®—é«˜äº®æ•ˆæœ
    recalculateHighlightEffect();
}

document.addEventListener('DOMContentLoaded', () => {
    // é¡µé¢åŠ è½½æ—¶ï¼Œç«‹å³æ ¹æ®é»˜è®¤æ—¥æœŸå¡«å……ä¸€æ¬¡æ¦œå•
    updateLeaderboards();

    // ä¸ºæ—¥æœŸé€‰æ‹©å™¨æ·»åŠ äº‹ä»¶ç›‘å¬å™¨
    const dateSelector = document.getElementById('date-selector');
    dateSelector.addEventListener('change', updateLeaderboards);

    // ç›‘å¬çª—å£å¤§å°å˜åŒ–ï¼Œä»¥è‡ªé€‚åº”é«˜äº®æ•ˆæœ (è¿™æ˜¯æ‚¨åŸæœ‰çš„é€»è¾‘)
    window.addEventListener('resize', recalculateHighlightEffect);
});

// è¿™æ˜¯æ‚¨åŸæœ‰çš„é«˜äº®è®¡ç®—é€»è¾‘ï¼Œç°åœ¨å·²ç»è¢«æ–°çš„ `recalculateHighlightEffect` å‡½æ•°å’Œäº‹ä»¶ç›‘å¬å™¨æ›¿ä»£
/*
document.addEventListener('DOMContentLoaded', () => {
    // ... åŸæœ‰é€»è¾‘ ...
});
window.addEventListener('resize', () => {
    // ... åŸæœ‰é€»è¾‘ ...
});
*/
</script>

<section class="hero teaser">
Â  <div class="container is-max-desktop">
Â  Â  Â  Â  <div class="content has-text-centered">
Â  Â  Â  Â  Â  <img src="./static/images/overview.jpg" alt="overview examples" />
Â  Â  Â  Â  Â  <p>Scoring the Optical Character Recognition (OCR) capabilities of Large Multimodal Models (LMMs) has witnessed growing interest. Existing benchmarks have highlighted the impressive performance of LMMs in text recognition; however, their abilities in certain challenging tasks, such as text localization, handwritten content extraction, and logical reasoning, remain underexplored. To bridge this gap, we introduce OCRBench v2, a large-scale bilingual text-centric benchmark with currently the most comprehensive set of tasks (4X more tasks than the previous multi-scene benchmark OCRBench), the widest coverage of scenarios (31 diverse scenarios), and thorough evaluation metrics, with 10,000 human-verified question-answering pairs and a high proportion of difficult samples. Moreover, we construct a private test set with 1,500 manually annotated images. The consistent evaluation trends observed across both public and private test sets validate the OCRBench v2's reliability. After carefully benchmarking state-of-the-art LMMs, we find that most LMMs score below 50 (100 in total) and suffer from five-type limitations, including less frequently encountered text recognition, fine-grained perception, layout perception, complex element parsing, and logical reasoning.</p>
Â  Â  </div>
</section>


<section class="section" id="BibTeX">
Â  <div class="container is-max-desktop content">
Â  Â  <h2 class="title">BibTeX</h2>
Â  Â  <pre><code></code>@misc{fu2024ocrbenchv2improvedbenchmark,
Â  Â  title={OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning},Â 
Â  Â  author={Ling Fu and Zhebin Kuang and Jiajun Song and Mingxin Huang and Biao Yang and Yuzhe Li and Linghao Zhu and Qidi Luo and Xinyu Wang and Hao Lu and Zhang Li and Guozhi Tang and Bin Shan and Chunhui Lin and Qi Liu and Binghong Wu and Hao Feng and Hao Liu and Can Huang and Jingqun Tang and Wei Chen and Lianwen Jin and Yuliang Liu and Xiang Bai},
Â  Â  year={2024},
Â  Â  eprint={2501.00321},
Â  Â  archivePrefix={arXiv},
Â  Â  primaryClass={cs.CV},
Â  Â  url={https://arxiv.org/abs/2501.00321},Â 
}</code></pre>
Â  </div>
</section>


<footer class="footer">
Â  <div class="container">
Â  Â  <div class="content has-text-centered">
Â  Â  Â  <a class="icon-link" href="https://arxiv.org/abs/2501.00321">
Â  Â  Â  Â  <i class="fas fa-file-pdf"></i>
Â  Â  Â  </a>
Â  Â  Â  <a class="icon-link" href="https://github.com/Yuliang-Liu/MultimodalOCR" class="external-link" disabled>
Â  Â  Â  Â  <i class="fab fa-github"></i>
Â  Â  Â  </a>
Â  Â  </div>
Â  Â  <div class="columns is-centered">
Â  Â  Â  <div class="column is-8">
Â  Â  Â  Â  <div class="content">
Â  Â  Â  Â  Â  <p>
Â  Â  Â  Â  Â  Â  This website is website adapted from <a href="https://nerfies.github.io/">Nerfies</a> , licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
Â  Â  Â  Â  Â  Commons Attribution-ShareAlike 4.0 International License</a>.
Â  Â  Â  Â  Â  </p>
Â  Â  Â  Â  </div>
Â  Â  Â  </div>
Â  Â  </div>
Â  </div>
</footer>

</body>
</html>
