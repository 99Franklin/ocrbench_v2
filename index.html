<!DOCTYPE html>

<html>

<head>

Â  <meta charset="utf-8">

Â  <meta name="description"

Â  Â  Â  Â  content="OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning ">

Â  <meta name="keywords" content="OCRBench v2">

Â  <meta name="viewport" content="width=device-width, initial-scale=1">

Â  <title>OCRBench v2</title>



Â  <!-- Global site tag (gtag.js) - Google Analytics -->

Â  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>

Â  <script>

Â  Â  window.dataLayer = window.dataLayer || [];



Â  Â  function gtag() {

Â  Â  Â  dataLayer.push(arguments);

Â  Â  }



Â  Â  gtag('js', new Date());



Â  Â  gtag('config', 'G-PYVRSFMDRL');

Â  </script>



Â  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"

Â  Â  Â  Â  rel="stylesheet">



Â  <link rel="stylesheet" href="./static/css/bulma.min.css">

Â  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">

Â  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">

Â  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">

Â  <link rel="stylesheet"

Â  Â  Â  Â  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

Â  <link rel="stylesheet" href="./static/css/index.css">

Â  <link rel="icon" href="./static/images/web.png">

Â  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">





Â  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

Â  <script defer src="./static/js/fontawesome.all.min.js"></script>

Â  <script src="./static/js/bulma-carousel.min.js"></script>

Â  <script src="./static/js/bulma-slider.min.js"></script>

Â  <script src="./static/js/index.js"></script>

</head>

<body>



<nav class="navbar" role="navigation" aria-label="main navigation">

Â  <div class="navbar-brand">

Â  Â  <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">

Â  Â  Â  <span aria-hidden="true"></span>

Â  Â  Â  <span aria-hidden="true"></span>

Â  Â  Â  <span aria-hidden="true"></span>

Â  Â  </a>

Â  Â  </div>

Â  Â 

</nav>





<section class="hero">

Â  <div class="hero-body">

Â  Â  <div class="container is-max-desktop">

Â  Â  Â  <div class="columns is-centered">

Â  Â  Â  Â  <div class="column has-text-centered">

Â  Â  Â  Â  Â  <h1 class="title is-1 publication-title">OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning</h1>

Â Â 

Â  Â  Â  Â  Â  <div class="column has-text-centered">

Â  Â  Â  Â  Â  Â  <div class="publication-links">

Â  Â  Â  Â  Â  Â  Â  <!-- PDF Link. -->

Â  Â  Â  Â  Â  Â  Â  <span class="link-block">

Â  Â  Â  Â  Â  Â  Â  Â  <a href="https://arxiv.org/abs/2501.00321"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â class="external-link button is-normal is-rounded is-dark">

Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="icon">

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <i class="ai ai-arxiv"></i>

Â  Â  Â  Â  Â  Â  Â  Â  Â  </span>

Â  Â  Â  Â  Â  Â  Â  Â  Â  <span>arXiv</span>

Â  Â  Â  Â  Â  Â  Â  Â  </a>

Â  Â  Â  Â  Â  Â  Â  </span>

Â  Â  Â  Â  Â  Â  Â  <!-- Code Link. -->

Â  Â  Â  Â  Â  Â  Â  <span class="link-block">

Â  Â  Â  Â  Â  Â  Â  Â  <a href="https://github.com/Yuliang-Liu/MultimodalOCR"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â class="external-link button is-normal is-rounded is-dark">

Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="icon">

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <i class="fab fa-github"></i>

Â  Â  Â  Â  Â  Â  Â  Â  Â  </span>

Â  Â  Â  Â  Â  Â  Â  Â  Â  <span>Code</span>

Â  Â  Â  Â  Â  Â  Â  Â  Â  </a>

Â  Â  Â  Â  Â  Â  Â  </span>

Â  Â  Â  Â  Â  Â  Â  <!-- Dataset Link. -->

Â  Â  Â  Â  Â  Â  Â  <span class="link-block">

Â  Â  Â  Â  Â  Â  Â  Â  <a href="https://drive.google.com/file/d/1Hk1TMu--7nr5vJ7iaNwMQZ_Iw9W_KI3C/view?usp=sharing"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â class="external-link button is-normal is-rounded is-dark">

Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="icon">

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <i class="far fa-images"></i>

Â  Â  Â  Â  Â  Â  Â  Â  Â  </span>

Â  Â  Â  Â  Â  Â  Â  Â  Â  <span>Data</span>

Â  Â  Â  Â  Â  Â  Â  Â  Â  </a>

Â  Â  Â  Â  Â  Â  Â  Â </span>

Â  Â  Â  Â  Â  Â  Â  <span class="link-block">

Â  Â  Â  Â  Â  Â  Â  Â  <a href="https://huggingface.co/datasets/ling99/OCRBench_v2" class="external-link button is-normal is-rounded is-dark">

Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="icon has-text-white">

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <i class="fa-solid fa-trophy" aria-hidden="true"></i>

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <!-- <p style="font-size:18px">ğŸ†</p> -->

Â  Â  Â  Â  Â  Â  Â  Â  Â  </span>

Â  Â  Â  Â  Â  Â  Â  Â  Â  <span>Huggingface</span>

Â  Â  Â  Â  Â  Â  Â  Â  </a>

Â  Â  Â  Â  Â  Â  Â  </span>

Â  Â  Â  Â  Â  Â  </div>



Â  Â  Â  Â  Â  </div>

Â  Â  Â  Â  </div>

Â  Â  Â  </div>

Â  Â  </div>

Â  </div>

</section>



Â  <head>

Â  <meta charset="UTF-8" />

Â  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>

Â  <title>Leaderboard</title>

Â  <style>

Â  Â  body {

Â  Â  Â  background-color: #ffffff;

Â  Â  Â  font-family: Arial, sans-serif;

Â  Â  Â  margin: 0;

Â  Â  Â  padding: 0;

Â  Â  }



Â  Â  .section {

Â  Â  Â  padding: 2rem 1rem;

Â  Â  }



Â  Â  .container {

Â  Â  Â  max-width: 1200px;

Â  Â  Â  margin: auto;

Â  Â  }



Â  Â  h2.title {

Â  Â  Â  font-size: 2rem;

Â  Â  Â  margin-bottom: 1rem;

Â  Â  Â  text-align: center;

Â  Â  Â  color: #333;

Â  Â  }



Â  Â  .content p {

Â  Â  Â  font-size: 1rem;

Â  Â  Â  font-weight: 600;

Â  Â  Â  margin-top: 2rem;

Â  Â  Â  margin-bottom: 0.5rem;

Â  Â  Â  text-align: center;

Â  Â  }



Â  Â  table {

Â  Â  Â  width: 100%;

Â  Â  Â  max-width: 100%;

Â  Â  Â  border-collapse: collapse;

Â  Â  Â  margin: 0 auto 2rem auto;

Â  Â  Â  font-size: 14px;

Â  Â  Â  text-align: center;

Â  Â  Â  box-shadow: 0 0 8px rgba(0,0,0,0.05);

Â  Â  }



Â  Â  thead {

Â  Â  Â  background-color: #e6f0fa;

Â  Â  Â  color: #333;

Â  Â  }



Â  Â  thead tr td {

Â  Â  Â  font-weight: bold;

Â  Â  Â  padding: 0.6rem;

Â  Â  Â  border-bottom: 2px solid #ccc;

Â  Â  }



Â  Â  tbody tr td {

Â  Â  Â  padding: 0.5rem;

Â  Â  Â  border-bottom: 1px solid #eee;

Â  Â  }



Â  Â  tbody tr:nth-child(even) {

Â  Â  Â  background-color: #f9fcff;

Â  Â  }



Â  Â  tbody tr:hover {

Â  Â  Â  background-color: #e0f3ff;

Â  Â  Â  transition: background-color 0.2s ease;

Â  Â  }



Â  Â  @media (max-width: 768px) {

Â  Â  Â  table {

Â  Â  Â  Â  font-size: 12px;

Â  Â  Â  }

Â  Â  }



Â  Â  .table-title {

Â  Â  Â  font-weight: bold;

Â  Â  Â  text-align: center;

Â  Â  Â  margin: 2rem 0 1rem 0;

Â  Â  }



Â  Â  table {

Â  Â  Â  position: relative;Â  Â  Â  Â  Â  Â  Â  Â /* è®©ä¼ªå…ƒç´ å®šä½åŸºå‡† */

Â  Â  Â  border-collapse: collapse;

Â  Â  }

Â  Â Â 

Â  Â  table td:nth-child(4),

Â  Â  table th:nth-child(4) {

Â  Â  Â  position: relative;

Â  Â  Â  z-index: 2;Â 

Â  Â  Â  font-weight: 700;

Â  Â  Â  background: rgba(240,248,255,.60);

Â  Â  Â  border-bottom: none!important;Â  Â  /* å–æ¶ˆåˆ†éš”çº¿ï¼Œé¿å…è¢«æˆªæ–­ */

Â  Â  }

Â  Â Â 

Â  Â  /* è¡Œæ–‘é©¬çº¹å¯¹ç¬¬ 4 åˆ—å¤±æ•ˆ */

Â  Â  table tr:nth-child(even) td:nth-child(4){

Â  Â  Â  background: rgba(240,248,255,.60);

Â  Â  }

Â  Â Â 

Â  Â  /* ç¬¬ä¸€/æœ€åä¸€è¡Œåœ†è§’ */

Â  Â  table tr:first-childÂ  td:nth-child(4){border-top-left-radius:12px;border-top-right-radius:12px}

Â  Â  table tr:last-childÂ  Â td:nth-child(4){border-bottom-left-radius:12px;border-bottom-right-radius:12px}

Â  Â Â 

Â  Â  /* ---------- è¿è´¯è™šåŒ–ä¼ªå…ƒç´  ---------- */

Â  Â  table::after{

Â  Â  Â  content:'';

Â  Â  Â  position:absolute;

Â  Â  Â  top:0; bottom:0;

Â  Â  Â  left:var(--avg-left,0);Â  Â  Â  Â  Â  Â  /* ç”± JS åŠ¨æ€å†™å…¥ */

Â  Â  Â  width:var(--avg-width,0);Â  Â  Â  Â  Â  /* ç”± JS åŠ¨æ€å†™å…¥ */

Â  Â  Â  border-radius:12px;

Â  Â  Â  pointer-events:none;

Â  Â  Â  background:rgba(240,248,255,.25);

Â  Â  Â  box-shadow:0 0 25px 16px rgba(100,150,255,.45);

Â  Â  Â  z-index:0;

Â  Â  }

Â  Â Â 

Â  </style>



Â  <script>

Â  document.addEventListener('DOMContentLoaded', () => {

Â  Â  /* å¯¹é¡µé¢é‡Œæ¯å¼ è¡¨æ‰§è¡Œä¸€æ¬¡å®šä½è®¡ç®— */

Â  Â  document.querySelectorAll('table').forEach(table => {

Â  Â  Â  /* å–è¡¨å¤´ or ç¬¬ä¸€è¡Œé‡Œçš„ç¬¬ 4 ä¸ªå•å…ƒæ ¼ */

Â  Â  Â  const avgCell = table.querySelector('tr:first-child th:nth-child(4), tr:first-child td:nth-child(4)');

Â  Â  Â  if (!avgCell) return;Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â /* æ²¡æ‰¾åˆ°å°±è·³è¿‡ */

Â Â 

Â  Â  Â  /* è¡¨æ ¼ & å•å…ƒæ ¼ç›¸å¯¹è§†çª—çš„çŸ©å½¢ */

Â  Â  Â  const tableRect = table.getBoundingClientRect();

Â  Â  Â  const cellRectÂ  = avgCell.getBoundingClientRect();

Â Â 

Â  Â  Â  /* è®¡ç®— Average åˆ—å·¦ä¾§åˆ°è¡¨æ ¼å·¦ä¾§çš„è·ç¦»ï¼Œä»¥åŠåˆ—å®½åº¦ */

Â  Â  Â  const leftÂ  = cellRect.leftÂ  - tableRect.left;

Â  Â  Â  const width = cellRect.width;

Â Â 

Â  Â  Â  /* å†™å…¥ CSS è‡ªå®šä¹‰å±æ€§ï¼Œä¾› table::after ä½¿ç”¨ */

Â  Â  Â  table.style.setProperty('--avg-left',Â  `${left}px`);

Â  Â  Â  table.style.setProperty('--avg-width', `${width}px`);

Â  Â  });

Â  });

Â Â 

Â  /* å¦‚æœé¡µé¢ä»¥åæœ‰çª—å£å¤§å°å˜åŒ–ï¼Œé™„å¸¦è‡ªé€‚åº”ï¼ˆå¯é€‰ï¼‰ */

Â  window.addEventListener('resize', () => {

Â  Â  document.querySelectorAll('table').forEach(table => {

Â  Â  Â  const avgCell = table.querySelector('tr:first-child th:nth-child(4), tr:first-child td:nth-child(4)');

Â  Â  Â  if (!avgCell) return;

Â  Â  Â  const tableRect = table.getBoundingClientRect();

Â  Â  Â  const cellRectÂ  = avgCell.getBoundingClientRect();

Â  Â  Â  const leftÂ  = cellRect.left - tableRect.left;

Â  Â  Â  const width = cellRect.width;

Â  Â  Â  table.style.setProperty('--avg-left',Â  `${left}px`);

Â  Â  Â  table.style.setProperty('--avg-width', `${width}px`);

Â  Â  });

Â  });

Â  </script>

Â Â 

</head>

<body>



<section class="section">

Â  <div class="container">

Â  Â  <h2 class="title">Leaderboard on Private data</h2>

Â  Â  <div class="content">



Â  Â  Â  <p class="table-title">Performance of LMMs on English tasks</p>

Â  Â  Â  <table>

Â  Â  Â  Â  <thead>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>Rank</td>

Â  Â  Â  Â  Â  Â  <td>Method</td>

Â  Â  Â  Â  Â  Â  <td>LLM Size</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">Average</td>

Â  Â  Â  Â  Â  Â  <td>Recognition</td>

Â  Â  Â  Â  Â  Â  <td>Referring</td>

Â  Â  Â  Â  Â  Â  <td>Spotting</td>

Â  Â  Â  Â  Â  Â  <td>Extraction</td>

Â  Â  Â  Â  Â  Â  <td>Parsing</td>

Â  Â  Â  Â  Â  Â  <td>Calculation</td>

Â  Â  Â  Â  Â  Â  <td>Understanding</td>

Â  Â  Â  Â  Â  Â  <td>Reasoning</td>



Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  </thead>

Â  Â  Â  Â  <tbody>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>1</td>

Â  Â  Â  Â  Â  Â  <td>Gemini-2.5-ProğŸ¥‡</td>

Â  Â  Â  Â  Â  Â  <td>-</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">59.3</td>

Â  Â  Â  Â  Â  Â  <td>70.9</td>

Â  Â  Â  Â  Â  Â  <td>45.8</td>

Â  Â  Â  Â  Â  Â  <td>13.4</td>

Â  Â  Â  Â  Â  Â  <td>93.7</td>

Â  Â  Â  Â  Â  Â  <td>26.9</td>

Â  Â  Â  Â  Â  Â  <td>84.6</td>

Â  Â  Â  Â  Â  Â  <td>75.8</td>

Â  Â  Â  Â  Â  Â  <td>63.0</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>2</td>

Â  Â  Â  Â  Â  Â  <td>Llama-3.1-Nemotron-Nano-VL-8B-V1ğŸ¥ˆ</td>

Â  Â  Â  Â  Â  Â  <td>-</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">56.4</td>

Â  Â  Â  Â  Â  Â  <td>62.9</td>

Â  Â  Â  Â  Â  Â  <td>61.3</td>

Â  Â  Â  Â  Â  Â  <td>68.6</td>

Â  Â  Â  Â  Â  Â  <td>88.2</td>

Â  Â  Â  Â  Â  Â  <td>10.0</td>

Â  Â  Â  Â  Â  Â  <td>44.1</td>

Â  Â  Â  Â  Â  Â  <td>75.3</td>

Â  Â  Â  Â  Â  Â  <td>41.0</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>3</td>

Â  Â  Â  Â  Â  Â  <td>Gemini1.5-ProğŸ¥‰</td>

Â  Â  Â  Â  Â  Â  <td>-</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">51.6</td>

Â  Â  Â  Â  Â  Â  <td>59.1</td>

Â  Â  Â  Â  Â  Â  <td>41.2</td>

Â  Â  Â  Â  Â  Â  <td>6.6</td>

Â  Â  Â  Â  Â  Â  <td>89.5</td>

Â  Â  Â  Â  Â  Â  <td>22.4</td>

Â  Â  Â  Â  Â  Â  <td>54.7</td>

Â  Â  Â  Â  Â  Â  <td>78.8</td>

Â  Â  Â  Â  Â  Â  <td>60.3</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>4</td>

Â  Â  Â  Â  Â  Â  <td>GPT-4o</td>

Â  Â  Â  Â  Â  Â  <td>-</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">47.6</td>

Â  Â  Â  Â  Â  Â  <td>58.6</td>

Â  Â  Â  Â  Â  Â  <td>23.4</td>

Â  Â  Â  Â  Â  Â  <td>0.0</td>

Â  Â  Â  Â  Â  Â  <td>87.4</td>

Â  Â  Â  Â  Â  Â  <td>23.1</td>

Â  Â  Â  Â  Â  Â  <td>51.6</td>

Â  Â  Â  Â  Â  Â  <td>74.4</td>

Â  Â  Â  Â  Â  Â  <td>62.3</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>5</td>

Â  Â  Â  Â  Â  Â  <td>Claude3.5-sonnet</td>

Â  Â  Â  Â  Â  Â  <td>-</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">47.5</td>

Â  Â  Â  Â  Â  Â  <td>52.9</td>

Â  Â  Â  Â  Â  Â  <td>24.9</td>

Â  Â  Â  Â  Â  Â  <td>2.5</td>

Â  Â  Â  Â  Â  Â  <td>86.9</td>

Â  Â  Â  Â  Â  Â  <td>23.8</td>

Â  Â  Â  Â  Â  Â  <td>61.4</td>

Â  Â  Â  Â  Â  Â  <td>74.4</td>

Â  Â  Â  Â  Â  Â  <td>53.0</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>6</td>

Â  Â  Â  Â  Â  Â  <td>Step-1V</td>

Â  Â  Â  Â  Â  Â  <td>-</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">46.8</td>

Â  Â  Â  Â  Â  Â  <td>56.7</td>

Â  Â  Â  Â  Â  Â  <td>27.4</td>

Â  Â  Â  Â  Â  Â  <td>2.6</td>

Â  Â  Â  Â  Â  Â  <td>86.3</td>

Â  Â  Â  Â  Â  Â  <td>33.3</td>

Â  Â  Â  Â  Â  Â  <td>42.6</td>

Â  Â  Â  Â  Â  Â  <td>76.6</td>

Â  Â  Â  Â  Â  Â  <td>48.7</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>7</td>

Â  Â  Â  Â  Â  Â  <td>InternVL3-14B</td>

Â  Â  Â  Â  Â  Â  <td>14B</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">46.8</td>

Â  Â  Â  Â  Â  Â  <td>55.8</td>

Â  Â  Â  Â  Â  Â  <td>24.5</td>

Â  Â  Â  Â  Â  Â  <td>2.1</td>

Â  Â  Â  Â  Â  Â  <td>89.3</td>

Â  Â  Â  Â  Â  Â  <td>21.0</td>

Â  Â  Â  Â  Â  Â  <td>59.5</td>

Â  Â  Â  Â  Â  Â  <td>72.0</td>

Â  Â  Â  Â  Â  Â  <td>50.0</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>8</td>

Â  Â  Â  Â  Â  Â  <td>Ovis2-8B</td>

Â  Â  Â  Â  Â  Â  <td>7B</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">46.1</td>

Â  Â  Â  Â  Â  Â  <td>54.2</td>

Â  Â  Â  Â  Â  Â  <td>20.9</td>

Â  Â  Â  Â  Â  Â  <td>0.0</td>

Â  Â  Â  Â  Â  Â  <td>83.6</td>

Â  Â  Â  Â  Â  Â  <td>24.2</td>

Â  Â  Â  Â  Â  Â  <td>54.7</td>

Â  Â  Â  Â  Â  Â  <td>74.1</td>

Â  Â  Â  Â  Â  Â  <td>57.3</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>9</td>

Â  Â  Â  Â  Â  Â  <td>InternVL3-8B</td>

Â  Â  Â  Â  Â  Â  <td>8B</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">45.3</td>

Â  Â  Â  Â  Â  Â  <td>49.7</td>

Â  Â  Â  Â  Â  Â  <td>22.3</td>

Â  Â  Â  Â  Â  Â  <td>0.2</td>

Â  Â  Â  Â  Â  Â  <td>86.8</td>

Â  Â  Â  Â  Â  Â  <td>22.4</td>

Â  Â  Â  Â  Â  Â  <td>57.0</td>

Â  Â  Â  Â  Â  Â  <td>70.7</td>

Â  Â  Â  Â  Â  Â  <td>53.0</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>10</td>

Â  Â  Â  Â  Â  Â  <td>GPT-4o-mini</td>

Â  Â  Â  Â  Â  Â  <td>-</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">44.1</td>

Â  Â  Â  Â  Â  Â  <td>55.3</td>

Â  Â  Â  Â  Â  Â  <td>21.8</td>

Â  Â  Â  Â  Â  Â  <td>0.0</td>

Â  Â  Â  Â  Â  Â  <td>85.4</td>

Â  Â  Â  Â  Â  Â  <td>20.6</td>

Â  Â  Â  Â  Â  Â  <td>45.2</td>

Â  Â  Â  Â  Â  Â  <td>75.5</td>

Â  Â  Â  Â  Â  Â  <td>49.0</td>

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â Â 

Â  Â  Â  Â  </tbody>

Â  Â  Â  </table>



Â  Â  Â  <p class="table-title">Performance of LMMs on Chinese tasks</p>

Â  Â  Â  <table>

Â  Â  Â  Â  <thead>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>Rank</td>

Â  Â  Â  Â  Â  Â  <td>Method</td>

Â  Â  Â  Â  Â  Â  <td>LLM Size</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">Average</td>

Â  Â  Â  Â  Â  Â  <td>Recognition</td>

Â  Â  Â  Â  Â  Â  <td>Extraction</td>

Â  Â  Â  Â  Â  Â  <td>Parsing</td>

Â  Â  Â  Â  Â  Â  <td>Understanding</td>

Â  Â  Â  Â  Â  Â  <td>Reasoning</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  </thead>

Â  Â  Â  Â  <tbody>



Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>1</td>

Â  Â  Â  Â  Â  Â  <td>Gemini-2.5-ProğŸ¥‡</td>

Â  Â  Â  Â  Â  Â  <td>-</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">62.2</td>

Â  Â  Â  Â  Â  Â  <td>72.0</td>

Â  Â  Â  Â  Â  Â  <td>74.0</td>

Â  Â  Â  Â  Â  Â  <td>35.2</td>

Â  Â  Â  Â  Â  Â  <td>90.0</td>

Â  Â  Â  Â  Â  Â  <td>39.7</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>2</td>

Â  Â  Â  Â  Â  Â  <td>Ovis2-8BğŸ¥ˆ</td>

Â  Â  Â  Â  Â  Â  <td>7B</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">56.0</td>

Â  Â  Â  Â  Â  Â  <td>61.0</td>

Â  Â  Â  Â  Â  Â  <td>67.7</td>

Â  Â  Â  Â  Â  Â  <td>43.6</td>

Â  Â  Â  Â  Â  Â  <td>82.0</td>

Â  Â  Â  Â  Â  Â  <td>25.6</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>3</td>

Â  Â  Â  Â  Â  Â  <td>Gemini1.5-ProğŸ¥‰</td>

Â  Â  Â  Â  Â  Â  <td>-</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">55.5</td>

Â  Â  Â  Â  Â  Â  <td>71.4</td>

Â  Â  Â  Â  Â  Â  <td>63.8</td>

Â  Â  Â  Â  Â  Â  <td>30.5</td>

Â  Â  Â  Â  Â  Â  <td>82.0</td>

Â  Â  Â  Â  Â  Â  <td>29.9</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>4</td>

Â  Â  Â  Â  Â  Â  <td>Kimi-VL-A3B-16B</td>

Â  Â  Â  Â  Â  Â  <td>16B</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">54.1</td>

Â  Â  Â  Â  Â  Â  <td>54.0</td>

Â  Â  Â  Â  Â  Â  <td>71.1</td>

Â  Â  Â  Â  Â  Â  <td>32.5</td>

Â  Â  Â  Â  Â  Â  <td>84.0</td>

Â  Â  Â  Â  Â  Â  <td>28.7</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>5</td>

Â  Â  Â  Â  Â  Â  <td>Step-1V</td>

Â  Â  Â  Â  Â  Â  <td>-</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">53.4</td>

Â  Â  Â  Â  Â  Â  <td>65.2</td>

Â  Â  Â  Â  Â  Â  <td>64.9</td>

Â  Â  Â  Â  Â  Â  <td>33.1</td>

Â  Â  Â  Â  Â  Â  <td>78.0</td>

Â  Â  Â  Â  Â  Â  <td>25.5</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>6</td>

Â  Â  Â  Â  Â  Â  <td>InternVL3-14B</td>

Â  Â  Â  Â  Â  Â  <td>14B</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">52.8</td>

Â  Â  Â  Â  Â  Â  <td>62.1</td>

Â  Â  Â  Â  Â  Â  <td>59.5</td>

Â  Â  Â  Â  Â  Â  <td>33.2</td>

Â  Â  Â  Â  Â  Â  <td>80.0</td>

Â  Â  Â  Â  Â  Â  <td>29.2</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>7</td>

Â  Â  Â  Â  Â  Â  <td>GLM-4v-9B</td>

Â  Â  Â  Â  Â  Â  <td>9B</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">51.7</td>

Â  Â  Â  Â  Â  Â  <td>60.6</td>

Â  Â  Â  Â  Â  Â  <td>65.2</td>

Â  Â  Â  Â  Â  Â  <td>32.4</td>

Â  Â  Â  Â  Â  Â  <td>82.0</td>

Â  Â  Â  Â  Â  Â  <td>18.2</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>8</td>

Â  Â  Â  Â  Â  Â  <td>Qwen2.5-VL-7B</td>

Â  Â  Â  Â  Â  Â  <td>8B</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">49.5</td>

Â  Â  Â  Â  Â  Â  <td>24.4</td>

Â  Â  Â  Â  Â  Â  <td>78.9</td>

Â  Â  Â  Â  Â  Â  <td>33.1</td>

Â  Â  Â  Â  Â  Â  <td>82.0</td>

Â  Â  Â  Â  Â  Â  <td>29.0</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>9</td>

Â  Â  Â  Â  Â  Â  <td>InternVL3-8B</td>

Â  Â  Â  Â  Â  Â  <td>8B</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">49.0</td>

Â  Â  Â  Â  Â  Â  <td>57.7</td>

Â  Â  Â  Â  Â  Â  <td>55.8</td>

Â  Â  Â  Â  Â  Â  <td>29.9</td>

Â  Â  Â  Â  Â  Â  <td>72.0</td>

Â  Â  Â  Â  Â  Â  <td>29.4</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>

Â  Â  Â  Â  Â  <tr>

Â  Â  Â  Â  Â  Â  <td>10</td>

Â  Â  Â  Â  Â  Â  <td>Claude3.5-sonnet</td>

Â  Â  Â  Â  Â  Â  <td>-</td>

Â  Â  Â  Â  Â  Â  <td class="highlight-average">48.4</td>

Â  Â  Â  Â  Â  Â  <td>34.2</td>

Â  Â  Â  Â  Â  Â  <td>62.5</td>

Â  Â  Â  Â  Â  Â  <td>35.2</td>

Â  Â  Â  Â  Â  Â  <td>78.0</td>

Â  Â  Â  Â  Â  Â  <td>32.2</td>

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  </tr>



Â  Â  Â  Â </tbody>

Â  Â  Â  </table>



Â  Â  Â  <br>Â 



Â  Â  Â  <style>

Â  Â  Â  Â  .info-box {

Â  Â  Â  Â  Â  background-color: #f5f9fc; /* æ›´åŠ æ¥è¿‘ç™½è‰²çš„è“ç°è‰² */

Â  Â  Â  Â  Â  border-left: 3px solid #aacbe3; /* æŸ”å’Œä¸€ç‚¹çš„è“è‰²è¾¹æ¡† */

Â  Â  Â  Â  Â  padding: 0.3em 1em; /* æ›´å°çš„ä¸Šä¸‹é—´è· */

Â  Â  Â  Â  Â  margin-bottom: 0.8em;

Â  Â  Â  Â  Â  border-radius: 4px;

Â  Â  Â  Â  Â  font-family: Arial, sans-serif;

Â  Â  Â  Â  Â  text-align: left; /* æ˜ç¡®å·¦å¯¹é½ */

Â  Â  Â  Â  Â  color: #333; /* æ›´æŸ”å’Œçš„æ·±ç°è‰²æ–‡æœ¬ */

Â  Â  Â  Â  Â  font-size: 14px;

Â  Â  Â  Â  Â  line-height: 1.5;

Â  Â  Â  Â  }

Â  Â  Â Â 

Â  Â  Â  Â  .info-title {

Â  Â  Â  Â  Â  font-weight: bold;

Â  Â  Â  Â  Â  margin-bottom: 0.3em;

Â  Â  Â  Â  }

Â  Â  Â  </style>

Â  Â  Â Â 

Â  Â  Â  <div class="info-box">

Â  Â  Â  Â  <p>We aim to update this benchmark every quarter. We sincerely welcome community contributions. If you have open-source models on Hugging Face or accessible APIs, sharing them with us would greatly help improve and expand the leaderboard. You can contact us at: ling_fu@hust.edu.cn</p>

Â  Â  Â  </div>

Â  Â  Â Â 

Â  Â  Â  <div class="info-box">

Â  Â  Â  Â  <p>We have observed that some methods adopt absolute encoding for prompt inputs when tackling specialized tasks. For example, Qwen2.5VL uses a format like {"bbox_2d": [x1, y1, x2, y2], "text_content": "xxx"} for text spotting. After modifying the prompt accordingly, Qwen2.5VL-7B achieved a text spotting score of 51.6 on public data, showing a significant improvement compared to the default prompt currently used in OCRBench v2. We encourage you to share the evaluation results using prompts adapted to your model's input format. This will help us further improve and refine the leaderboard.</p>

Â  Â  Â  </div>

Â  Â  Â Â 

Â  Â  </div>

Â  </div>

</section>



<section class="hero">

Â  <div class="hero-body">

Â  Â  <div class="container is-max-desktop">

Â  Â  Â  <div class="columns is-centered">

Â  Â  Â  Â  <div class="column has-text-centered">

Â  Â  Â  Â  Â  <h2 class="subtitle is-3 publication-subtitle">

Â  Â  Â  Â  Â  Â OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and ReasoningÂ 

Â  Â  Â  Â  Â  </h2>

Â  Â  Â  Â  Â  <div class="is-size-5 publication-authors">

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Ling Fu</a><sup>1</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Zhebin Kuang</a><sup>1</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Jiajun Song</a><sup>1</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Mingxin Huang</a><sup>2</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Biao Yang</a><sup>1</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Yuzhe Li</a><sup>1</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Linghao Zhu</a><sup>1</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Qidi Luo</a><sup>1</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Xinyu Wang</a><sup>3</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Hao Lu</a><sup>1</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Zhang Li</a><sup>1</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Guozhi Tang</a><sup>4</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Bin Shan</a><sup>4</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Chunhui Lin</a><sup>4</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Qi Liu</a><sup>4</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Binghong Wu</a><sup>4</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Hao Feng</a><sup>4</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Hao Liu</a><sup>4</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Can Huang</a><sup>4</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Jingqun Tang</a><sup>4</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Wei Chen</a><sup>1</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Lianwen Jin</a><sup>2</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Yuliang Liu</a><sup>1</sup>,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block">

Â  Â  Â  Â  Â  Â  Â Xiang Bai</a><sup>1</sup></span>

Â  Â  Â  Â  Â  </div>

Â  Â  Â  Â  Â  <br>

Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  <div class="is-size-5 publication-authors">

Â  Â  Â  Â  Â  Â  <span class="author-block"><sup>1</sup>Huazhong University of Science and Technology,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block"><sup>2</sup>South China University of Technology,</span>

Â  Â  Â  Â  Â  Â  <span class="author-block"><sup>3</sup>University of Adelaide,</span>Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  <span class="author-block"><sup>4</sup>ByteDance</span>

Â  Â  Â  Â  Â  </div>

Â  Â  Â  Â  Â  Â <br>

Â Â 

Â  Â  Â  Â  Â  </div>

Â  Â  Â  Â  </div>

Â  Â  Â  </div>

Â  Â  </div>

Â  </div>

</section>



Â Â 

<section class="hero teaser">

Â  <div class="container is-max-desktop">

Â  Â  Â  Â  <div class="content has-text-centered">

Â  Â  Â  Â  Â  <img src="./static/images/overview.jpg" alt="overview examples" />

Â  Â  Â  Â  Â  <p>Scoring the Optical Character Recognition (OCR) capabilities of Large Multimodal Models (LMMs) has witnessed growing interest. Existing benchmarks have highlighted the impressive performance of LMMs in text recognition; however, their abilities in certain challenging tasks, such as text localization, handwritten content extraction, and logical reasoning, remain underexplored. To bridge this gap, we introduce OCRBench v2, a large-scale bilingual text-centric benchmark with currently the most comprehensive set of tasks (4X more tasks than the previous multi-scene benchmark OCRBench), the widest coverage of scenarios (31 diverse scenarios), and thorough evaluation metrics, with 10,000 human-verified question-answering pairs and a high proportion of difficult samples. Moreover, we construct a private test set with 1,500 manually annotated images. The consistent evaluation trends observed across both public and private test sets validate the OCRBench v2's reliability. After carefully benchmarking state-of-the-art LMMs, we find that most LMMs score below 50 (100 in total) and suffer from five-type limitations, including less frequently encountered text recognition, fine-grained perception, layout perception, complex element parsing, and logical reasoning.</p>

Â  Â  </div>

Â Â 

</section>





<section class="section" id="BibTeX">

Â  <div class="container is-max-desktop content">

Â  Â  <h2 class="title">BibTeX</h2>

Â  Â  <pre><code></code>@misc{fu2024ocrbenchv2improvedbenchmark,

Â  Â  title={OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning},Â 

Â  Â  author={Ling Fu and Zhebin Kuang and Jiajun Song and Mingxin Huang and Biao Yang and Yuzhe Li and Linghao Zhu and Qidi Luo and Xinyu Wang and Hao Lu and Zhang Li and Guozhi Tang and Bin Shan and Chunhui Lin and Qi Liu and Binghong Wu and Hao Feng and Hao Liu and Can Huang and Jingqun Tang and Wei Chen and Lianwen Jin and Yuliang Liu and Xiang Bai},

Â  Â  year={2024},

Â  Â  eprint={2501.00321},

Â  Â  archivePrefix={arXiv},

Â  Â  primaryClass={cs.CV},

Â  Â  url={https://arxiv.org/abs/2501.00321},Â 

}</code></pre>

Â  </div>

</section>





<footer class="footer">

Â  <div class="container">

Â  Â  <div class="content has-text-centered">

Â  Â  Â  <a class="icon-link"

Â  Â  Â  Â  Â href="https://arxiv.org/abs/2501.00321">

Â  Â  Â  Â  <i class="fas fa-file-pdf"></i>

Â  Â  Â  </a>

Â  Â  Â  <a class="icon-link" href="https://github.com/Yuliang-Liu/MultimodalOCR" class="external-link" disabled>

Â  Â  Â  Â  <i class="fab fa-github"></i>

Â  Â  Â  </a>

Â  Â  </div>

Â  Â  <div class="columns is-centered">

Â  Â  Â  <div class="column is-8">

Â  Â  Â  Â  <div class="content">

Â  Â  Â  Â  Â  <p>

Â  Â  Â  Â  Â  Â  This website is website adapted from <a href="https://nerfies.github.io/">Nerfies</a> , licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative

Â  Â  Â  Â  Â  Commons Attribution-ShareAlike 4.0 International License</a>.

Â  Â  Â  Â  Â  </p>

Â  Â  Â  Â  </div>

Â  Â  Â  </div>

Â  Â  </div>

Â  </div>

</footer>



</body>

</html>
